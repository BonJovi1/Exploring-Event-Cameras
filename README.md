# Exploring-Event-Cameras
Asynchronous event trajectory generation, event stream simulation and flow estimation

### Abstract
Event Cameras are causing a paradigm shift in the com- puter vision world due to multiple advantages over conven- tional cameras, including high temporal resolution, high dynamic range and low power consumption. This makes it an ideal choice for capturing fast motion. In this work, we explore various works in this domain that help us under- stand the concept of event-based data. We implement a tra- jectory generation network as proposed in EventCap [13], which helps track events in 2D space in an asynchronous manner. We also explore how we can simulate neuromor- phic data from conventional high fps videos, in the absence of an event camera. Lastly, we also take a look at represent- ing event-based data as images, for deep learning and CNN applications. In particular, we use a self-supervised flow network to estimate optical flow for data exhibiting human motion. Our work on this project is in continuum, as we try to implement motion deblurring using simulated event streams. 

If you find our study useful for your research, kindly acknowledge it appropriately and cite our work:
```
@misc{exploring-event-cameras,
  author = {Abhinav Gupta and Amogh Tiwari and Avinash Sharma},
  title = {Exploring Event Cameras: Event Trajectory Generation, Neuromorphic Data Simulation and Event Based Flow Estimation},
  year = {2020},
  howpublished = {\url{https://github.com/BonJovi1/Exploring-Event-Cameras}}
}
```

For any questions, kindly contact 
- Abhinav Gupta - abhinav.g@students.iiit.ac.in
- Amogh Tiwari - amogh.tiwari@research.iiit.ac.in

